{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from scipy.stats import randint as sp_randint\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for file in ['../data/MovAve15_Data.csv', '../data/MovAve30_Data.csv',\n",
    "             '../data/MovAve60_Data.csv', '../data/MovAve90_Data.csv']:\n",
    "    dfs[file[14:16]] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKFold:\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def split(self, df, y, groups=None):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        import numpy as np\n",
    "\n",
    "        sk = StratifiedKFold(random_state=0, n_splits=self.n_splits, shuffle=True)\n",
    "\n",
    "        train_all = df[df['year'] < 2019]\n",
    "\n",
    "        for train_idx, valid_idx in sk.split(np.zeros(train_all.shape[0]), train_all['year']):\n",
    "            yield (train_idx, valid_idx)\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold_Scaled:\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def split(self, df, y, groups=None):\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        import numpy as np\n",
    "\n",
    "        sk = StratifiedKFold(random_state=0, n_splits=self.n_splits, shuffle=True)\n",
    "\n",
    "        train_all = df[df['year'] < 1]\n",
    "\n",
    "        for train_idx, valid_idx in sk.split(np.zeros(train_all.shape[0]),\n",
    "                                             LabelEncoder().fit_transform(df['year'])):\n",
    "            yield (train_idx, valid_idx)\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpt/.local/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator accuracy for 15: 0.5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpt/.local/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator accuracy for 30: 0.5153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpt/.local/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator accuracy for 60: 0.5171\n",
      "best estimator accuracy for 90: 0.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpt/.local/lib/python3.6/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "preds = {}\n",
    "tests = {}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "\n",
    "    data_scaled = df.copy()\n",
    "    scalers = {}\n",
    "\n",
    "    for col in df:\n",
    "        if df[col].nunique() > 2:\n",
    "            scalers[col] = MinMaxScaler((-1, 1))\n",
    "            data_scaled[col] = scalers[col].fit_transform(df[col].values.reshape(-1, 1))\n",
    "\n",
    "    train = data_scaled[data_scaled['year'] < 1]\n",
    "    test = data_scaled[data_scaled['year'] == 1]\n",
    "\n",
    "    x_train = train.drop(['Target_Var'], axis=1)\n",
    "    y_train = train['Target_Var']\n",
    "\n",
    "    x_test = test.drop(['Target_Var'], axis=1)\n",
    "    y_test = test['Target_Var']\n",
    "    \n",
    "    with open('best_lr_model_{}.pckl'.format(name), 'rb') as f:\n",
    "        lr = pickle.load(f)\n",
    "    #with open('best_lr_model_cv_{}.pckl'.format(name), 'rb') as f:\n",
    "    #    lr_cv = pickle.load(f)\n",
    "    \n",
    "    accuracy = lr.score(x_test, y_test)\n",
    "    print('best estimator accuracy for {}: {:.4f}'.format(name, accuracy))\n",
    "    preds[name] = lr.predict_proba(x_test)[:,1]\n",
    "    tests[name] = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_accuracy_data(threshold, prediction, actual):\n",
    "    '''\n",
    "    This function will take two series of equal length and only calculate \n",
    "    accuracy for predictions that meet the threshold criteria. \n",
    "    '''\n",
    "    accuracies = []\n",
    "    my_list = []\n",
    "    for preds, truth in zip(prediction, actual):\n",
    "        if preds >= threshold:\n",
    "            accuracies.append(1 == truth)\n",
    "        elif preds <= (1-threshold):\n",
    "            accuracies.append(0 == truth)\n",
    "        else:\n",
    "            continue\n",
    "    if len(accuracies) == 0:\n",
    "        accuracy = None\n",
    "        subsample_percent = 0\n",
    "    else:\n",
    "        accuracy = accuracies.count(True)/len(accuracies)\n",
    "        subsample_percent = len(accuracies)/len(prediction)\n",
    "    return [threshold, accuracy, subsample_percent]\n",
    "\n",
    "\n",
    "'''\n",
    "For the below, update predictions list to be your list of predict probas in\n",
    "15,30,60,90 order and same for tests list being actual outcomes. \n",
    "Change 'your_model_type' (2 serperate inputs) below to some 2-4 character string\n",
    "that describes your model. (RF, NN, GB, LR, etc etc)\n",
    "Please push csv to git once complete.\n",
    "'''\n",
    "thresholds = [.52, .54, .55, .56]\n",
    "predictions = [preds['15'], preds['30'], preds['60'], preds['90']]\n",
    "tests = [tests['15'], tests['30'], tests['60'], tests['90']]\n",
    "mov_avs = [15,30,60,90]\n",
    "lists_ = []\n",
    "for p, a, m in zip(predictions, tests, mov_avs):\n",
    "    for t in thresholds:\n",
    "        lists_.append(check_accuracy_data(t, p, a) + [m, 'LR'])\n",
    "        \n",
    "df = pd.DataFrame(lists_)\n",
    "df.columns = ['Threshold', 'Accuracy', 'Percent_of_Samples', 'Dataset', 'Model']\n",
    "\n",
    "# Save file with your model name \n",
    "df.to_csv('../data/accuracy_dataframe_lr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
